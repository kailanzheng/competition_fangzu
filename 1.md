### 1.线性回归

1)模型

线性回归假设输出与各个输入之间是线性关系，例如：
$$
\mathrm{price} = w_{\mathrm{area}} \cdot \mathrm{area} + w_{\mathrm{age}} \cdot \mathrm{age} + b
$$
2)损失函数衡量预测值与真实值之间的误差，此处为平方损失：
$$
L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2.
$$
3)优化函数-随机梯度下降

1. 当模型和损失函数形式较为简单时，误差最小化问题：a. easy可以直接得到->解析解 b. 优化算法迭代->数值解

2. 模型优化的过程：初始化模型参数->对参数在数据上迭代->在负梯度方向（平均损失有关模型参数的导数）上移动参数来更新
   $$
   (\mathbf{w},b) \leftarrow (\mathbf{w},b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b)
   $$
   

### 2.softmax与交叉熵损失函数

1)为什么使用softmax？

a. 当输出层的输出值范围不确定，难以直观判断;

b. 真实label是离散值，则这些真实label与获得的不确定范围的输出值之间的误差难以衡量。

2)softmax得到什么？

将输出值变换为正且和为1的概率分布，且不改变预测类别的输出。
$$
\hat{y}_1, \hat{y}_2, \hat{y}_3 = \text{softmax}(o_1, o_2, o_3)
$$

$$
\hat{y}1 = \frac{ \exp(o_1)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y}2 = \frac{ \exp(o_2)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y}3 = \frac{ \exp(o_3)}{\sum_{i=1}^3 \exp(o_i)}.
$$
3)矢量计算可以提高计算效率，进一步的对小批量数据做矢量计算，其中的加法运算使用了广播机制

4)为什么使用交叉熵损失函数？

相比于平方损失估计，交叉熵损失函数更适合衡量两个概率分布差异的测量函数。例如：在真实label中，只有正确类别值为1,其他均为0,则当使用平方损失函数时，预测值中非正确类别的softmax值为0.2,0.2的情况比预测值中非正确类别的softmax值为0,0.4的情况的损失要小很多，虽然二者都有相同正确的分类预测结果。

5)交叉熵损失函数的使用
$$
H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)},
$$
其中带下标的yj(i)是向量y(i)中非0即1的元素，y(i)为一个样本的label值。

交叉熵只关心对图像中出现的物体类别的预测概率，非正确的值均为0,不计于损失函数中，假如正确类别只有一个，则损失函数变成：
$$
H(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}) = -\log \hat y_{y^{(i)}}^{(i)}
$$
假设训练数据集的样本数为n，交叉熵损失函数定义为
$$
\ell(\boldsymbol{\Theta}) = \frac{1}{n} \sum_{i=1}^n H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ),
$$
其中Θ代表模型参数。同样地，如果每个样本只有一个标签，那么交叉熵损失可以简写成
$$
\ell(\boldsymbol{\Theta}) = -(1/n) \sum_{i=1}^n \log \hat y_{y^{(i)}}^{(i)}
$$
从另一个角度来看，我们知道最小化ℓ(Θ)等价于最大化
$$
\exp(-n\ell(\boldsymbol{\Theta}))=\prod_{i=1}^n \hat y_{y^{(i)}}^{(i)}
$$
即最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率。



### 3.多层感知机

下图展示了一个多层感知机的神经网络图

![Image Name](https://cdn.kesci.com/upload/image/q5ho684jmh.png)



### 4.文本预处理

- 读入文本
- 分词
- 建立字典，将每个词映射到一个唯一的索引（index）
- 将文本从词的序列转换为索引的序列，方便输入模型



### 5.语言模型

一段自然语言文本可以看作是一个离散时间序列，给定一个长度为T的词的序列w1,w2,…,wT，语言模型的目标就是评估该序列是否合理，即计算该序列的概率：P(w1,w2,…,wT).



### 6.循环神经网络基础

基于当前的输入与过去的输入序列，预测序列的下一个字符。循环神经网络引入一个隐藏变量H，用Ht表示H在时间步t的值。Ht的计算基于Xt和Ht−1，可以认为Ht记录了到当前字符为止的序列信息，利用Ht对序列的下一个字符进行预测。

![Image Name](https://cdn.kesci.com/upload/image/q5jkm0v44i.png?imageView2/0/w/640/h/640)